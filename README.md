# ğŸ¤ Real-Time Speech-to-Text ASR Web App

This is a Streamlit-based web application for **Real-Time Automatic Speech Recognition (ASR)**. The app allows users to upload `.wav` or `.flac` audio files and receive transcriptions using a trained deep learning model.

---

## ğŸ“Œ Features

- âœ… Upload audio files (.wav or .flac)
- âœ… Extracts MFCC features from speech
- âœ… Predicts phoneme sequences using a TensorFlow-trained ASR model
- âœ… Decodes output using a greedy CTC decoder
- âœ… Displays waveform of the audio signal
- âœ… Real-time inference and transcription

---

## ğŸ§  Model Details

- **Model Type**: CTC-based RNN/GRU/LSTM model
- **Input**: MFCC features with shape `(time_steps, 13)`
- **Output**: Logits over vocabulary tokens
- **Framework**: TensorFlow 2.x
- **Saved Format**: TensorFlow SavedModel (loaded using `TFSMLayer`)

---

## ğŸ—‚ Project Structure

```
RealTime-ASR-Project/
â”œâ”€â”€ app/
â”‚   â””â”€â”€ streamlit_app.py        # Main Streamlit app
â”œâ”€â”€ models/
â”‚   â””â”€â”€ predict_tf/             # SavedModel directory
â”œâ”€â”€ audio/                      # (Optional) Test audio samples
â””â”€â”€ README.md                   # This file
```

---

## ğŸš€ How to Run

1. **Install Requirements**:
   ```bash
   pip install streamlit librosa tensorflow matplotlib
   ```

2. **Start the App**:
   ```bash
   streamlit run app/streamlit_app.py
   ```

3. **Use the Interface**:
   - Upload a `.wav` or `.flac` file
   - See the waveform and transcription in real time

---

## ğŸ§ª Example

| Input Audio        | Output Transcription |
|--------------------|----------------------|
| `hello_world.wav`  | `hello world`        |

---

## âš™ï¸ Configuration

- **Model Path**: Change the `MODEL_SAVED_DIR` variable in `streamlit_app.py` if needed
- **Max Time Steps**: Modify `MAX_TIME_STEPS` if your model expects a different input shape

---

## ğŸ“– Glossary

- **ASR (Automatic Speech Recognition)**: Converts speech audio to text using deep learning.
- **CTC (Connectionist Temporal Classification)**: Loss function and decoding method for unaligned sequence data.
- **MFCC (Mel-Frequency Cepstral Coefficients)**: Widely used feature set for speech analysis.

---


## ğŸ“ License

This project is licensed under the MIT License. Feel free to modify and use it as needed.
